{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "51c2832e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ed2a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Kangaroo.csv') # Load a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350a172f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cc1d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7ae75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef708d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_columns = df.columns.tolist()\n",
    "df_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eca70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() # Summary info of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275d4a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14ad574",
   "metadata": {},
   "source": [
    "### Summary of infos collected\n",
    "- Shape: 80,368 x 53\n",
    "- Some columns are likely unnecessary: url, id?, unnamed,...\n",
    "- Many columns misses a lot information:\n",
    "100%: monthlyCost, hasBalcony, accessibleDisabledPeople"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94f81fe",
   "metadata": {},
   "source": [
    "## Data cleaning\n",
    "1. Remove duplicate : No duplicates in data set\n",
    "2. Remove irrelevant columns: URL, Unnamed:0, \n",
    "3. Remove columns missing a lot info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2babc9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum() # Check for duplicate rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bf1cc2",
   "metadata": {},
   "source": [
    "### Removing Duplicates\n",
    "Duplicates do not bring any new information and can bias statistics. We remove them first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a8ac8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Drop irrelevant columns\n",
    "df_cleaned = df.drop(columns=[\"Unnamed: 0\", \"url\"])\n",
    "df_cleaned.shape\n",
    "df_cleaned.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aaca86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Trim Whitespace in Strings\n",
    "\n",
    "str_cols = df_cleaned.select_dtypes(include='object').columns #Selects columns that are of type string or mixed object\n",
    "for col in str_cols:\n",
    "    df_cleaned[col] = df_cleaned[col].apply(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "df_cleaned.describe(include='all') # Summary statistics of the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0749a795",
   "metadata": {},
   "source": [
    "### Remove rows with missing `price`\n",
    "This column is essential for predictive modeling and analysis, so we discard rows without it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c95e529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all rows with missing price\n",
    "initial_shape = df_cleaned.shape\n",
    "df_cleaned = df_cleaned.dropna(subset=['price'])\n",
    "print(f\"Deleted {initial_shape[0] - df_cleaned.shape[0]} rows without a price.\")\n",
    "print(\"New shape after dropping missing prices:\", df_cleaned.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fbe03c",
   "metadata": {},
   "source": [
    "### Drop columns with more than 90% missing values (except `hasSwimmingPool`)\n",
    "Columns with more than 90% missing values are considered too sparse to be reliable. However, we retain `hasSwimmingPool` due to its interpretability and potential usefulness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b1ef7eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped columns: ['monthlyCost', 'hasDressingRoom', 'diningRoomSurface', 'hasHeatPump', 'hasThermicPanels', 'hasBalcony', 'gardenOrientation', 'hasAirConditioning', 'hasArmoredDoor', 'hasFireplace', 'accessibleDisabledPeople']\n"
     ]
    }
   ],
   "source": [
    "# Drop columns with >90% missing values, but keep 'hasSwimmingPool'\n",
    "cols_to_drop = df_cleaned.columns[\n",
    "    (df_cleaned.isnull().mean() > 0.9) & (df_cleaned.columns != 'hasSwimmingPool')\n",
    "]\n",
    "df_cleaned = df_cleaned.drop(columns=cols_to_drop)\n",
    "print(\"Dropped columns:\", list(cols_to_drop))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdea8e0",
   "metadata": {},
   "source": [
    "### Imputing Remaining Missing Values\n",
    "We now fill remaining missing values to avoid issues in later analysis:\n",
    "- For **numerical columns**, we use the **median** to avoid the effect of outliers.\n",
    "- For **categorical columns**, we use the **mode** (most frequent value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d680e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep a copy of the dataset before imputing\n",
    "df_before_impute = df_cleaned.copy()\n",
    "\n",
    "for col in df_cleaned.select_dtypes(include='number').columns:\n",
    "    if df_cleaned[col].isnull().sum() > 0:\n",
    "        median_val = df_cleaned[col].median()\n",
    "        df_cleaned[col] = df_cleaned[col].fillna(median_val)\n",
    "\n",
    "for col in df_cleaned.select_dtypes(include='object').columns:\n",
    "    if df_cleaned[col].isnull().sum() > 0:\n",
    "        mode_val = df_cleaned[col].mode()[0]\n",
    "        df_cleaned[col] = df_cleaned[col].fillna(mode_val)\n",
    "        \n",
    "df_cleaned = df_cleaned.infer_objects(copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52893878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned dataset\n",
    "df_cleaned.to_csv('Kangaroo_cleaned.csv', index=False)\n",
    "print(\"Cleaned dataset saved as 'Kangaroo_cleaned_presentation.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67fee8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_ids = df_cleaned['id'].duplicated().sum()\n",
    "print(f\"Found {duplicate_ids} duplicated IDs.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
